# Emma Voice Console - State Machine Refactor

## ğŸ¯ What Was Implemented

### 1. **useVoiceConsole.js Hook** (`src/hooks/useVoiceConsole.js`)

A self-contained React hook that manages the complete voice lifecycle with a deterministic state machine:

**States:**
- `idle` â†’ Ready to start
- `listening` â†’ Microphone active, speech recognition running
- `processing` â†’ Handling command/intent
- `speaking` â†’ Emma responding with speech synthesis
- `error` â†’ Something went wrong

**Key Features:**
- âœ… **VAD (Voice Activity Detection):** Auto-stops after 2 seconds of silence
- âœ… **Wake Phrase Gate:** "Emma, start analysis" required before commands
- âœ… **Female Voice Selection:** Searches for female/UK voices (Sara, Zira, etc.)
- âœ… **60-Second Inactivity Timeout:** Auto-stops if no speech detected
- âœ… **Push-to-Talk Support:** Optional PTT mode
- âœ… **Proper Audio Cleanup:** MediaStream tracks properly closed
- âœ… **Browser Compatibility:** Handles Chrome/Edge SpeechRecognition

### 2. **intentRouter.js** (`src/lib/intentRouter.js`)

Clean intent mapping and command execution:

**Supported Commands:**
- `"Emma, start analysis"` â†’ Wake phrase (opens console)
- `"run sync"` / `"synchronize"` â†’ Triggers `/api/emma-sync`
- `"help"` â†’ Lists available commands
- `"stop"` â†’ Stops listening

**Easy to Extend:**
```javascript
case "openStrategy":
  navigate('/strategy');
  return "Opening strategy dashboard.";
```

### 3. **VoiceConsoleNew.jsx** (`src/components/VoiceConsoleNew.jsx`)

Clean, modern UI with three-button control:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Voice Console      [Ready]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Say "Emma, start analysis",     â”‚
â”‚ then "run sync".                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [ğŸ™ï¸ Start] [â¹ï¸ Stop] [ğŸ”‡ Cancel] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Buttons:**
- **Start** (ğŸ™ï¸): Begin listening
- **Stop** (â¹ï¸): End session and close mic
- **Cancel** (ğŸ”‡): Stop Emma from speaking

## ğŸ”§ How It Works

### Flow Diagram

```
User Clicks "Start"
    â†“
Request Mic Permission
    â†“
Start VAD (Voice Activity Detection)
    â†“
Start SpeechRecognition
    â†“
STATE: listening
    â†“
User says: "Emma, start analysis"
    â†“
Wake Phrase Detected â†’ Speak confirmation
    â†“
User says: "run sync"
    â†“
Intent Detected: runSync
    â†“
STATE: processing
    â†“
Fetch /api/emma-sync
    â†“
STATE: speaking
    â†“
Speak: "Synchronization complete, Ash."
    â†“
STATE: idle
```

### VAD (Voice Activity Detection)

```javascript
// Auto-stops after 2 seconds of silence
const analyser = ctx.createAnalyser();
analyser.fftSize = 2048;

// Calculate RMS energy
const rms = Math.sqrt(sum / data.length);

if (rms < 0.015) {  // silence threshold
  silentFrames++;
  if (silentFrames > 120) {  // ~2 seconds at 60fps
    stop();  // Auto-stop
  }
}
```

### Female Voice Selection

```javascript
const voices = window.speechSynthesis.getVoices();

// Search for female voices
const femaleVoice = voices.find(v => 
  /female|sara|en-gb|uk|ar-xa|ze|laila|maya/i.test(`${v.name} ${v.voiceURI}`)
);

if (femaleVoice) {
  utterance.voice = femaleVoice;
  utterance.pitch = 1.02;  // Slightly higher for feminine tone
}
```

## ğŸ“¦ File Structure

```
src/
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useVoiceConsole.js       # State machine hook
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ intentRouter.js          # Command mapping
â”œâ”€â”€ components/
â”‚   â””â”€â”€ VoiceConsoleNew.jsx      # UI component
â””â”€â”€ App.jsx                       # Import VoiceConsoleNew
```

## ğŸš€ Usage

### Basic Setup (Already Done)

```jsx
// src/App.jsx
import VoiceConsoleNew from './components/VoiceConsoleNew'

function App() {
  return (
    <Layout>
      {/* ...routes... */}
      <VoiceConsoleNew />
    </Layout>
  )
}
```

### Test Commands

1. **Click "ğŸ™ï¸ Start"** â†’ Mic activates, status: "Listening..."
2. **Say: "Emma, start analysis"** â†’ Hears confirmation
3. **Say: "run sync"** â†’ Triggers sync, hears: "Synchronization complete, Ash."
4. **Say: "help"** â†’ Lists available commands
5. **Click "â¹ï¸ Stop"** â†’ Mic closes, status: "Ready"

## ğŸ¯ Improvements Over Old System

| Issue | Old System | New System |
|-------|-----------|-----------|
| **State Management** | Ad-hoc flags (`isStopped`, `isListening`) | Deterministic state machine |
| **Duplicate Code** | Two `stop()` functions | Single comprehensive `stop()` |
| **Voice Selection** | Basic, didn't wait for voices | Proper loading + female search |
| **Auto-Stop** | Manual only | VAD + 60s inactivity |
| **Wake Phrase** | Missing | Required: "Emma, start analysis" |
| **Command Routing** | Scattered in component | Centralized `intentRouter.js` |
| **Error Handling** | Minimal | Proper mic denial, recognition errors |
| **Audio Cleanup** | Incomplete | MediaStream tracks properly closed |

## ğŸ”’ Browser Compatibility

- âœ… **Chrome 25+** (webkitSpeechRecognition)
- âœ… **Edge 79+** (Chromium-based)
- âœ… **Safari 14.1+** (limited, requires user gesture)
- âŒ **Firefox** (No SpeechRecognition support)

**Detection:**
```javascript
const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const isSupported = !!(Recognition && window.speechSynthesis);
```

## ğŸ“ Adding New Commands

### Step 1: Update Intent Router

```javascript
// src/lib/intentRouter.js

export async function handleIntent(intent, text) {
  switch (intent) {
    // ... existing cases ...
    
    case "openStrategy":
      window.location.href = "/strategy";
      return "Opening strategy dashboard, Ash.";
      
    case "generateReport":
      const res = await fetch("/api/generate-report", { method: "POST" });
      return "Report generated successfully.";
      
    default:
      return "I didn't catch that command.";
  }
}
```

### Step 2: Update Local Intent Mapper (Optional)

```javascript
// src/hooks/useVoiceConsole.js

const localIntent = useCallback((text) => {
  const t = text.toLowerCase().trim();
  
  if (t.includes("open strategy")) return "openStrategy";
  if (t.includes("generate report")) return "generateReport";
  
  // ... existing intents ...
}, []);
```

## ğŸ› Debugging

### Enable Console Logging

```javascript
// src/hooks/useVoiceConsole.js

rec.onresult = async (e) => {
  console.log('ğŸ™ï¸ Speech result:', e.results);
  // ... existing code ...
};

speak.onend = () => {
  console.log('ğŸ”Š Speech ended');
  // ... existing code ...
};
```

### Check Voice List

Open browser console:
```javascript
window.speechSynthesis.getVoices().forEach(v => 
  console.log(v.name, v.lang, v.gender)
);
```

### Test VAD Threshold

Adjust silence detection sensitivity:
```javascript
const voice = useVoiceConsole({
  vadThreshold: 0.020,  // Higher = more sensitive to silence
  // ...
});
```

## ğŸ¨ Customization

### Change Wake Phrase

```javascript
const voice = useVoiceConsole({
  wakePhrase: "hey emma",  // New wake phrase
  // ...
});
```

### Adjust Inactivity Timeout

```javascript
const voice = useVoiceConsole({
  inactivityMs: 120_000,  // 2 minutes instead of 60 seconds
  // ...
});
```

### Enable Push-to-Talk

```javascript
const voice = useVoiceConsole({
  pushToTalk: true,  // Hold button to talk
  // ...
});

// In component:
<button 
  onMouseDown={() => voice.pttDown()}
  onMouseUp={() => voice.pttUp()}
>
  Hold to Talk
</button>
```

### Change Voice Locale

```javascript
const voice = useVoiceConsole({
  locale: "en-GB",  // British English
  // locale: "ar-XA",  // Arabic
  // ...
});
```

## ğŸ“Š Commit

```
commit d536f4a
Author: Ashraf Kahoush
Date: November 4, 2025

refactor: voice console with state machine architecture

- Add useVoiceConsole.js hook with deterministic state machine
- Implement VAD (Voice Activity Detection) for auto-silence detection
- Add wake phrase gate: 'Emma, start analysis'
- Implement female voice selection with proper voice loading
- Add intentRouter.js for clean command mapping
- Create VoiceConsoleNew.jsx with Start/Stop/Cancel controls
- Support 60s inactivity timeout and PTT mode
- Integrate runSync command to /api/emma-sync endpoint

Fixes:
- Removes duplicate stop() function issue
- Proper female voice selection with fallback
- Deterministic lifecycle: idle â†’ listening â†’ processing â†’ speaking â†’ idle
- Browser compatibility handling for mic permissions
```

## âœ… Testing Checklist

- [ ] Click "ğŸ™ï¸ Start" â†’ Status changes to "Listeningâ€¦"
- [ ] Say "Emma, start analysis" â†’ Hear female voice confirmation
- [ ] Say "run sync" â†’ Hear "Synchronization complete, Ash."
- [ ] Say "help" â†’ Hear list of commands
- [ ] Stay silent for 2 seconds â†’ Auto-stops (VAD)
- [ ] Wait 60 seconds â†’ Auto-stops (inactivity timeout)
- [ ] Click "â¹ï¸ Stop" â†’ Mic closes immediately
- [ ] Click "ğŸ”‡ Cancel" while Emma speaking â†’ Speech stops
- [ ] Check console for female voice selection log
- [ ] Test on Chrome/Edge (should work)
- [ ] Test on Firefox (should show "not supported" message)

---

**Status:** âœ… Ready for testing  
**Branch:** main  
**Commit:** d536f4a  
**Dev Server:** http://localhost:3000
